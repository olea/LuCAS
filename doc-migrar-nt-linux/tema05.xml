<?xml version="1.0" encoding="iso-8859-1"?>
<sect1 id="tema05"> 

	<title>Rendimiento</title>

    <para>Las comparaciones detalladas en equipos informáticos similares, muestran que
	los UNIX/Linux son más estables, requieren menos administración, y son más rápidos en
	operaciones de lectura-escritura al disco duro que Microsoft Windows NT y Windows 2000,
	a pesar de los últimos avances del sistema de ficheros NTFS de Microsoft. No se deben
	encontrar las pruebas de la refutación creíble de estas declaraciones, dadas las búsquedas
	en la web y los rumores industriales. Las revistas más importantes de computación tienen
	prohibido mediante licencias de Microsoft, la muestra de tales pruebas detalladas.
	Efectivamente, sólo pueden mostrarse un conjunto de pruebas peraltadas y obtusas para
	resaltar una superioridad particular de un NT o de una máquina de 2000 a un UNIX/Linux bajo
	teóricas igualdades en la especificación del harware.</para>

    <para>En el mundo real, evidencias corporativas han mostrado concluyentemente que las
	máquinas UNIX/Linux funcionan durante meses, e incluso años, sin la necesidad de una
	reinicialización, y los conocidos cuelgues son raros. Esto no es así con Windows NT, que
	es propenso al desastre sin ninguna razón aparente incluso después haber aplicado todos
	sus Service Packs.Administradores competentes tanto del mundo de Microsoft como fuera
	de él Microsoft recomienda que, siempre que sea posible, se abandone Microsoft Windows
	NT. Las pruebas muestran que Windows 2000 es cuantificablemente más estable que NT,
	pero aún no al mismo nivel que UNIX/Linux. Windows 2000 también ofrece una mejor
	supervisión de fallos y mejores herramientas de recuperación que su antecesor. Microsoft
	promete que el servidor .NET ofrecerá mayor estabilidad por parte del núcleo del sistema
	operativo. Respecto a XP, en palabras de Bill Gates: "Las características de informes de
	errores integradas en Office XP y Windows XP no han dado una enorme cantidad de
	avisos de incidencias de los usuarios..."</para>

	<para>Con un gran coste adicional, la naturaleza menos fiable de los sistemas operativos
	de Microsoft puede solventarse "agrupándolos" (clustering) para <emphasis>Alta
	Disponibilidad</emphasis> (HA, high avilability), que introduce un nivel más de complejidad
	para la mayor parte de los administradores formados en Windows. Microsoft
	<emphasis>Datacenter</emphasis> es un producto de clustering dispensado sólamente
	por ciertos vendedores certificados por Microsoft. Tomando como base las aplicaciones
	utilizadas a nivel local, se crea específicamente una solución Windows 2000 para un sitio
	en concreto. Cada implementación es por lo tanto diferente, y la creación del sistema implica
	a menudo consultas entre el vendedor, los ingenieros del fabricante del equipo informático,
	y Microsoft. La solución se captura permanentemente sobre CDs y se transporta al lugar
	dónde reside el equipo del cliente para su instalación. Para los líderes de las TI, es inevitable
	cierta pérdida de control puesto que no se permite que los administradores locales realicen
	ningún cambio, sin embargo podría afirmarse que ésta es una demanda lógica puesto que
	el acuerdo Datacenter garantiza a menudo un funcionamiento continuado del 99,999%.</para>

    <para>Puesto que no se permite ningún cambio a una aplicación de Microsoft Datacenter
	una vez que se ha implantado, por ejemplo Service Packs o Hotfixes, hay deficiencias
	preocupantes en la dependencia de una organización alejada para tales puestas al día
	críticas, según lo discutido abajo con relación a la seguridad. Además, el vendedor requiere
	la supervisión durante las 24 horas del sistema Datacenter, de modo que la red local debe
	proporcionar el acceso completo a distancia a una organización foránea, que introduce
	preocupaciones de seguridad de red.</para>

    <para>El clustering en máquinas UNIX/Linux es algo rutinario, pero hay una categoría
	adicional de la cual los sistemas operativos de Microsoft carecen especialmente: el
	clustering de <emphasis>Alto Rendimiento</emphasis> (HPC o high performance). La
	mayoría de los distribuidores principales de UNIX ofrecen servicios de clusters HA y HPC
	bajo un alto coste, configurado por personal especialmente capacitado para un entorno
	basado en un objetivo crítico como por ejemplo la investigación científica, el comercio
	electrónico o las finanzas.  Desde hace algunos años existe una alternativa HPC viable y
	de bajo coste basada en Linux. Para clusters con las configuraciones de HA y HPC Linux
	facilita una plataforma a coste comparativamente bajo (pero con el mismo alto rendimiento
	en la productividad) para fines tales como la detección de fallos en servidores web como
	Apache o para la investigación científica a un velocidad muy alta utilizando paquetes Open
	Source como <emphasis>Beowulf</emphasis>. Efectivamente, muchas organizaciones
	académicas, científicas, y militares (tales como los laboratorios Sandia y Livermore en
	EE.UU.) han implantado clusters basados en Linux Beowulf. Algunas escuelas han
	descubierto el beneficio de la supercomputación a precios muy bajos creando clusters
	basados en Linux Beowulf a partir de ordenadores de escritorio (por supuesto mejorados
	con dispositivos especiales de red para adaptarse).</para>

	<para>De modo realista, la mayor parte de las aplicaciones informáticas comerciales no
	requerirían el tipo de beneficio forjado por un superordenador, sin emabargo es muy
	ilustrativo para ver cómo los UNIX/Linux puede fácilmente adaptarse a estos y otros muchos
	papeles mientras que los sistemas operativos de Microsoft sencillamente, no pueden, hacerlo.
	Debe considerarse que como con Microsoft Datacenter, tales sistemas UNIX/Linux de gama
	alta son implantados y gestionados generalmente por organizaciones exteriores con una gran
	limitación en los acuerdos para la administración local, sin embargo, toda la documentación
	y el software necesario para crear un Linux/Beowulf está <emphasis>libremente
	disponible</emphasis> procedente de la comunidad Open Source.</para>

	<para>En medio de los entornos de más bajo nivel que no requieren el rendimiento de HA
	o HPC, los sistemas operativos Windows no son tan fiables como los UNIX/Linux. La gran
	mayoría de los problemas en sistemas operativos Windows es causada por problemas de
	programación. Puesto que los servidores UNIX/Linux son mucho menos propensos a tales
	dificultades en la ejecución de las aplicaciones, la preocupación sobre fiabilidad en ellos es
	por lo tanto el equipo informático subyacente. Históricamente, tales fracasos son pocos, y
	efectivamente microscópicos con respecto a los cuelgues de los sistemas operativos
	Windows. Mientras que el mundo basado en Windows aborda la inestabilidad del sistema
	operativo agrupando algunos o muchos servidores para la protección de potenciales caídas,
	un solo servidor UNIX/Linux con hardware dual o multi-pathed puede generalmente reemplazar
	un cluster de servidores Windows sin la preocupación apreciable del tiempo de caida. Las
	historias de grandes cantidades de servidores Windows reemplazados por uno o varios de
	tipo UNIX/Linux son típicas en el mundo actual de las TI.</para>

    <para>El tiempo empleado en la "reinicialización" de máquinas Windows NT y 2000 puede
	ser costoso económicamente, pero también en la productivdad. Los cambios producidos en
	la configuración de una máquina NT por un administrador cualificado requieren a menudo
	una reinicialización completa, incluso para las alteraciones que en el mundo UNIX/Linux se
	considerarían rutinarias y triviales en una máquina en constante funcionamiento. Windows
	2000 y XP ha reducido considerablemente la cantidad de reinicializaciones requeridas por
	NT, aunque todavía se requieren en una frecuencia mucho mayor que en UNIX/Linux. La
	disponiblidad de aplicaciones sobre sistemas operativos Windows son por lo tanto menos
	robustas que en UNIX/Linux. Reiniciar el sistema para solucionar problemas, una técnica
	común en la administración de sistemas Microsoft, es una estrategia costosa y
	antiproductiva. Los líderes de IT mas comodones pueden encontrar grata la adopción de
	servidores Windows. Peor aún, pueden haber sido condicionados a creer que la
	<emphasis>"cultura del reinicio"</emphasis> es normal y aceptable. Después de todo,
	reiniciar es <emphasis>"fácil"</emphasis>. UNIX/Linux es modular por naturaleza,
	adaptándose con aplomo a las condiciones cambiantes. La resolución de errores y la
	administración en tiempo real es rutinaria, y un adminstrator generalmente puede aislar y/o
	<emphasis>"matar"</emphasis> y reiniciar programas concretos sin afectar al propio
	SO u otros programas. Las máquinas UNIX/Linux se ciñen a seguir, seguir y seguir...</para>

    <para>Los compradores potenciales de servidores Windows .NET deben ser conscientes
	de que es aún una conjetura arriesgada suponer que una organización pueda confiar en la
	nueva versión, especialmente donde la computación financiera o el comercio es una tarea
	habitual. A diferencia de UNIX/Linux, no existe un conjunto significativo de pruebas de la
	estabilidad de su núcleo. Tales datos para UNIX/Linux son ordinarios, y el progreso del
	desarrollo y las pruebas del núcleo de Linux es completamente visible para todas las partes
	interesadas.</para>

    <para>Uno de los comandos favoritos del administrador de sistemas UNIX/Linux es
	<command>uptime</command>, que muestra el tiempo transcurrido desde que la última
	reinicialización. A diferencia de los períodos típicos de días para Windows NT o una semana
	o dos para Windows 2000, este perído en UNIX/Linux se mide usualmente en meses, si no
	en años. Indudablemente algunos administradores de Windows obtienen períodos medios
	bastante altos con cuidado y atención diligentes, pero invariablemente esas máquinas no
	realizan tareas pesadas.</para>

    <para>Los aspectos complicados de la durabilidad en servidores Windows consisten en la
	necesidad de reinicializar como parte de las actividades rutinarias de puesta al día contra
	virus, esto quiere decir que <emphasis>incluso si los sistemas no llegaran a ser inestables
	aún requerirían un tiempo de reinicio</emphasis>. Según lo descrito más adelante, las
	máquinas UNIX/Linux no son susceptibles a tales problemas por virus. Por razones de la
	durabilidad y períodos largos de servicio sin interrupción, las tareas tales como el comercio
	electrónico y la manipulación crítica de datos son gestionadas con mayor eficiencia por
	servidores UNIX/Linux que por servidores Microsoft Windows.</para>

    <para>Con el mayor rendimiento y las capacidades multitarea proporcionadas por los
	sitemas UNIX/Linux , la cantidad de servidores puede reducirse cuando se emprende una
	migración desde servidores Microsoft Windows. Por utilizar una analogía, <emphasis>tirando
	de un carro es siempre mejor utilizar un caballo que doscientos pollos</emphasis>. Un
	número menor de máquinas significan mayor eficiencia, menos electricidad, y una integración
	más rápida de nuevas funcionalidades. Según lo descrito más adelante, las grandes
	organizaciones corporativas de las TI están encontrando que esto es absolutamente
	cierto.</para>

</sect1>
