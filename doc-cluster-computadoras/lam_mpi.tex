\chapter{LAM/MPI.}
\minitoc
\section{Introducción MPI.}
	El paso de mensajes es una tarea ampliamente usada en ciertas clases de máquinas paralelas,
especialmente aquellas que cuentan con memoria distribuida. Aunque existen muchas variaciones, el concepto
básico en el proceso de comunicación mediante mensajes es bien entendido. En los últimos 10 años, se ha
logrado un proceso substancial en convertir aplicaciones significativas hacia este tipo de tareas. Más
recientemente diferentes sistemas han demostrado que un sistema de paso de mensajes puede ser implementado
eficientemente y con un alto grado de portabilidad.

	Al diseñarse MPI, se tomaron en cuenta las características más atractivas de los sistemas existentes
para el paso de mensajes, en vez de seleccionar uno solo de ellos y adoptarlo como el estándar. Resultando
así, en una fuerte influencia para MPI los trabajos hechos por IBM, INTEL, NX/'', Express, nCUBE's Vernex,
p4 y PARMACS. Otras contribuciones importantes provienen de Zipcode, Chimp, PVM, Chameleon y PICL.

	La meta de MPI o Message Passing Interface (Interfaz de paso de mensajes), es el desarrollar un
estándar (que sea ampliamente usado) para escribir programas que implementen el paso de mensajes. Por lo cual
el interfaz intenta establecer para esto un estándar práctico, portable, eficiente y flexible.

	El esfuerzo para estandarizar MPI involucro a cerca de 60 personas de 40 organizaciones diferentes
principalmente de U.S.A. y Europa. La mayoría de los vendedores de computadoras concurrentes estaban involucrados
con MPI, así como con investigadores de diferentes universidades, laboratorios del gobierno e industrias. El
proceso de estandarización comenzó en el taller de estándares para el paso de mensajes en un ambiente con
memoria distribuida, patrocinado por el Centro de Investigación en Computación Paralela en Williamsbur Virginia
(Abril 29-30 de 1992). Se llego a una propuesta preliminar conocida como \textit{MPI1}, enfocada principalmente
en comunicaciones punto a punto sin incluir rutinas para comunicación colectiva y no presentaba tareas seguras. El
estándar final por el MPI fue presentado en la conferencia de Supercomputación en Noviembre de 1993, constituyéndose
así el foro para el MPI.

	En un ambiente de comunicación con memoria distribuida en la cual las rutinas de paso de mensajes de
nivel bajo, los beneficios de la estandarización son muy notorios. La principal ventaja al establecer un
estándar para el paso de mensajes es la portabilidad y el ser fácil de utilizar.

	MPI es un sistema complejo, el cual comprende 129 funciones, de las cuales la mayoría tiene muchos
parámetros y variantes.
	\newline
	
	\textbf{Metas del MPI}
	\begin{quote}
        \begin{itemize}
	\item Diseñar una interfaz de programación aplicable (no necesariamente para compiladores o sistemas que
implementan una librería).
        \item Permitir una comunicación eficiente. Evitando el copiar de memoria a memoria y permitiendo (donde
sea posible) la sobreposición de computación y comunicación, además de aligerar la comunicación con el procesador.
	\item Permitir implementaciones que puedan ser utilizadas en un ambiente heterogéneo.
	\item Permitir enlaces convenientes en C y Fortran 77 para el interfaz.
        \item Asumir un interfaz de comunicación seguro. El usuario no debe lidiar con fallas de comunicación.
Tales fallas son controladas por el subsistema de comunicación interior.
        \item Definir un interfaz que no sea muy diferente a los actuales, tales como PVM, NX, Express, p4, etc.,
y proveer de extensiones para permitir mayor flexibilidad.
        \item Definir un interfaz que pueda ser implementado en diferentes plataformas, sin cambios significativos
en el software y las funciones internas de comunicación.
	\item La semántica del interfaz debe ser independiente del lenguaje.
	\item La interfaz debe ser diseñada para producir tareas seguras.
	\end{itemize}
	\end{quote}
	
\subsection{Modelo de programación.}
        En el modelo de programación MPI, un computo comprende de uno o más procesos comunicados a través
de llamadas a rutinas de librerías para mandar (send) y recibir (receive) mensajes a otros procesos. En la
mayoría de las implementaciones de MPI, se crea un conjunto fijo de procesos al inicializar el programa, y un
proceso es creado por cada tarea. Sin embargo, estos procesos pueden ejecutar diferentes programas. De ahí que,
el modelo de programación MPI es algunas veces referido como \textit{MPMD} (multiple program multiple data) para
distinguirlo del modelo \textit{SPMD}, en el cual cada procesador ejecuta el mismo programa.

	Debido a que el número de procesos en un cómputo de MPI es normalmente fijo, se puede enfatizar en el
uso de los mecanismos para comunicar datos entre procesos. Los procesos pueden utilizar operaciones de
comunicación punto a punto para mandar mensajes de un proceso a otro, estas operaciones pueden ser usadas para
implementar comunicaciones locales y no estructuradas. Un grupo de procesos puede llamar colectivamente operaciones
de comunicación para realizar tareas globales tales como broadcast, etc. La habilidad de MPI para probar
mensajes da como resultado el soportar comunicaciones asíncronas. Probablemente una de las características
más importantes del MPI es el soporte para la programación modular. Un mecanismo llamado comunicador permite
al programador del MPI definir módulos que encapsulan estructuras internas de comunicación (estos módulos
pueden ser combinados secuencialmente y paralelamente).

\subsection{Bases.}
        Aunque MPI es un sistema complejo y multifacético, podemos resolver un amplio rango de problemas
usando seis de sus funciones, estas funciones inician y terminan un cómputo, identifican procesos, además de
mandar y recibir mensajes.
	\begin{itemize}
	\item\textbf{MPI\_INT:} Inicia un computo.\newline
MPI\_INT(int *argc,char ***argv), argc, argv son requeridos solo por el contexto del lenguaje C, en el cual
son los argumentos del programa principal.
        \item\textbf{MPI\_FINALIZE:} Termina un computo. MPI\_FINALIZE().
        \item \textbf{MPI\_COMM\_SIZE:} Determina el número de procesos en un computo.  \newline
MPI\_COMM\_SIZE(comm,size), IN comm comunicador(manejador[handle]), \newline
OUT size número de procesos en el grupo del comunicador(entero).
	\item\textbf{MPI\_COMM\_RANK:} Determina el identificador del proceso actual ``mi proceso''.\newline
MPI\_COMM\_RANK(comm,pid), IN comm comunicador (manejador[andel]), OUT pid identificador del proceso en el
grupo del comunicador(entero).
        \item\textbf{MPI{\_}SEND:} Manda un mensaje. MPI{\_}SEND(buf, count, datatype, dest, tag, comm). IN
buf dirección del buffer a enviar (tipo x), IN count número de elementos a enviar del buffer (entero>=0), IN
datatype tipo de datos del buffer a enviar (handle), IN dest identificador del proceso destino (entero), IN
tag message tag (entero), IN comm comunicador (handle)
	\item\textbf{MPI{\_}RECV:} Recive un mensaje. MPI{\_}RECV(buf,count,datatype,dest,tag,comm). OUT buf
dirección del buffer a recibir (tipo x), IN count número de elementos a recibir del buffer (entero>=0), IN
datatype tipo de datos del buffer a recibir (handle), IN source identificador del proceso fuente, o
MPI\_ANY\_SOURCE(entero), IN tag message tag, o MPI\_ANY\_TAG(entero), IN comm comunicador (handle), OUT status
estado del objeto (estado)
	\item\textbf{IN:} Significa que la función usa pero no modifica el parámetro.
	\item\textbf{OUT:} Significa que la función no usa pero puede modificar el parámetro.
	\item\textbf{INOUT:} Significa que la función usa y modifica el parámetro.
        \end{itemize}
	Todas las funciones (excepto las dos primeras) toman un manejador (handle) ``comunicador'' como
argumento. El comunicador identifica el grupo de procesos y el contexto en el cual la operación se debe
realizar. Como se menciono anteriormente, los comunicadores proveen un mecanismo para identificar subconjuntos
de procesos durante el desarrollo de programas modulares y para garantizar que los mensajes provistos con
diferentes propósitos no sean confundidos. Por ahora, es suficiente proveer el valor de default
MPI\_COMM\_WORLD, el cual identifica todos los procesos en un cómputo.

	Las funciones MPI{\_}INT y MPI{\_}FINALIZE son usadas para iniciar y terminar un computo MPI,
respectivamente MPI\_INIT debe ser llamada antes que cualquier otra función MPI y debe ser llamada solamente
una vez por proceso. Ninguna función MPI puede ser llamada después de MPI\_FINALIZE.

	Las funciones MPI\_COMM\_SIZE y MPI\_COMM\_BANK determinan el número de procesos en el cómputo actual
y el identificador (entero) asignado al proceso actual, respectivamente. Los procesos en un grupo de procesos
son identificados con un único y continuo número (entero), empezando en 0.

	El estándar del MPI no especifica como un cómputo paralelo es iniciado. Pero un mecanismo típico
podría ser el especificar desde la línea de comandos el número de procesos a crear.
        \newline

	\textbf{Determinismo:}
        \begin{itemize}
	\item El paso de mensajes en módulos de programación son por defecto no deterministicos; el orden de llegadas
de los mensajes enviados desde dos procesos A y B hacia un tercer proceso C, no esta definido. Pero, MPI
garantiza que dos mensajes enviados desde un proceso A, hacia otro proceso B, llegarán en el orden en que
fueron enviados.
	\item En el modelo de programación Tarea/Canal, el determinismo es garantizado al definir canales separados
para diferentes comunicaciones y al asegurar que cada canal tiene un solo escritor y un solo lector. Por lo
cual, un proceso C puede distinguir mensajes recibidos de A o B tal y como llegan en diferentes canales. MPI
no soporta canales directos, pero provee mecanismos similares; en particular, permite una operación de recibimiento
para especificar una fuente, tag y/o contexto.
        \end{itemize}
	\textbf{Especificaciones en el contexto del lenguaje C:}
        \begin{itemize}
	\item Los nombres de las funciones son tal y como se presentan en la definición del MPI pero solo con el
prefijo de MPI y la primer letra del nombre de la función en mayúsculas.
        \item Los valores de los estados son regresados como códigos enteros. El código de regreso para una
ejecución exitosa es MPI\_SUCESS.
	\item También esta definido un conjunto de códigos de error.
	\item Las constantes están en mayúsculas y son definidas en el archivo mpi.h
	\item Los handles son representados por tipos especialmente definidos en mpi.h
	\item Los parámetros de las funciones del tipo IN son pasados por valor, mientras que los parámetros
OUT y INOUT son pasados por referencia (como apuntadores).
	\item Las variables de estado (status) tiene el tipo MPI\_Status y es una estructura con campos status.
MPI\_SOURCE y status.MPI\_TAG.
	\item Los tipos de datos del MPI están definidos para cada tipo de datos de C: MPI\_CHAR, MPI\_INT,
MPI\_LONG\_INT, MPI\_UNSIGNED\_CHAR, etc.
	\end{itemize}

\subsection{Operaciones globales.}
        Como ya se ha explicado, los algoritmos paralelos ejecutan llamadas a operaciones para coordinar la
comunicación en múltiples procesos.
	Por ejemplo, todos los procesos pueden necesitar cooperar para invertir una matriz distribuida o para
sumar un conjunto de números distribuidos en cada proceso. Claramente, estas operaciones globales pueden ser
implementadas por un programador usando las funciones send y receive. Por conveniencia y para permitir la
optimización, MPI provee un conjunto especializado de funciones colectivas de comunicación que obtienen
operaciones de este tipo.

\subsection{Comunicación asíncrona.}
	La necesidad por tener una comunicación asíncrona puede presentarse cuando un computo necesita
acceder los elementos de un dato estructurado compartido en una manera no estructurada. Una implementación
aproximada es el encapsular los datos estructurados en un conjunto de tareas de datos especializados, en la
cual las peticiones de lectura y escritura pueden ser ejecutadas. Este método no es eficiente en MPI debido
a su modelo de programación MPMD.

	Una implementación alternativa con MPI, es el distribuir las estructuras de datos compartidas entre
los procesos existentes, los cuales deben solicitar periódicamente las solicitudes pendientes de lectura y
escritura. Para esto MPI presenta tres funciones MPI\_IPROBE, MPI{\_}PROBE, MPI{\_}GET{\_}COUNT.
	\begin{itemize}
	\item\textbf{MPI\_IPROBE:} chequea existencia de mensajes pendientes sin recibirlos, permitiéndonos
escribir programas que generan cómputos locales con el procesamiento de mensajes sin previo aviso. El mensaje
puede ser recibido usando MPI\_RECV.
	\item\textbf{MPI\_PROBE:} es utilizado para recibir mensajes de los cuales se tiene información
incompleta. El siguiente fragmento de código hace uso de estas funciones para recibir un mensaje de una fuente
desconocida y con un número de enteros desconocidos como contenido. Primero detecta la llegada del mensaje
utilizado MPI\_PROBE. Después, determina la fuente del mensaje y utiliza \textbf{MPI{\_}GET{\_}COUNT} para
conocer el tamaño del mensaje.Finalmente, direcciona un buffer par recibir el mensaje.
        \end{itemize}
\subsection{Modularidad.}

	Conocemos ya tres formas generales de composición que puede ser usadas en la construcción modular de
programas paralelos, a saber, secuencial, paralelo y concurrente.

	MPI soporta la programación modular a través de su mecanismo de comunicador (comm, el cual provee la
información oculta necesaria al construir un programa modular), al permitir la especificación de componentes
de un programa, los cuales encapsulan las operaciones internas de comunicación y proveen un espacio para el
nombre local de los procesos.

	Una operación de comunicación MPI siempre especifica un comunicador. Este identifica el grupo de
procesos que están comprometidos en el proceso de comunicación y el contexto en el cual la comunicación ocurre.
El grupo de procesos permite a un subconjunto de procesos el comunicarse entre ellos mismos usando identificadores
locales de procesos y el ejecutar operaciones de comunicación colectivas sin meter a otros procesos. El contexto
forma parte del paquete asociado con el mensaje. Una operación \emph{receive} puede recibir un mensaje solo si este fue
enviado en el mismo contexto. Si dos rutinas usan diferentes contextos para su comunicación interna, no puede
existir peligro alguno en confundir sus comunicaciones.

	A continuación se describen las funciones que permiten a los comunicadores ser usados más flexiblemente.
        \begin{itemize}
        \item\textbf{MPI\_COMM\_DUP:} Un programa puede crear un nuevo comunicador, conteniendo el mismo grupo
de procesos pero con un nuevo contexto para asegurar que las comunicaciones generadas para diferentes propósitos
no sean confundidas, este mecanismo soporta la composición paralela.
	\item\textbf{MPI\_COMM\_SPLIT:} Un programa puede crear un nuevo comunicador, conteniendo solo un subconjunto
del grupo de procesos. Estos procesos pueden comunicarse entre ellos sin riesgo de tener conflictos con otros
cómputos concurrentes. Este mecanismo soporta la composición paralela.
	\item\textbf{MPI\_INTERCOMM\_CREATE:} Un programa puede construir un intercomunicador, el cual enlaza
procesos en dos grupos. Soporta la composición paralela.
	\item\textbf{MPI\_COMM\_FREE:} Esta función puede ser utilizada para liberar el comunicador creado al usar
funciones anteriores.
        \end{itemize}
\subsection{Instalación.}
        El paquete rpm de LAM/MPI que se va ha instalar es el que nos provee el cd de Red Hat Linux 6.2, para llevar
a cabo su instalación se realizará lo siguiente:
	\begin{quote}
		\textit{{\$}$>$mount /mnt/cdrom}\newline
                \textit{{\$}$>$cd /mnt/cdrom/RedHat/RPMS/}\newline
                \textit{{\$}$>$rpm --ivh lam-6.3.1-4.i386.rpm}
	\end{quote}
	En el sitio web \url{http://www.lam-mpi.org/download/} se podrá obtener la última versión de dicho
software.

\subsection{Configuración.}
	En el directorio \textit{/usr/boot} crearemos los siguiente archivos con sus correspondientes
configuraciones.
        \begin{enumerate}
	\item Archivo conf.lam, se recogerá la topología de red utilizada.
        \begin{quote}\textit{lamd \$inet\_topo}\end{quote}
       	\item Archivo bhost.def, se añadirá al final los nombres de todos los nodos que forman parte del cluster.
       	\begin{em}
	\begin{quote}
		localhost
		pc1
		pc2
		\ldots
	\end{quote}
	\end{em}
        \end{enumerate}
        Para testear si la configuración es correcta se deberá de realizar lo siguiente:

        \begin{quote}\textit{{\$}$>$lamboot}\end{quote}
        Si la salida muestra algún error entonces es que hay algún problema con la instalación, comunicación
 entre nodos, etc.

\section{Compilación y ejecución de programas LAM/MPI}
	Se generará el siguiente fichero llamado \textit{makefile}, que tendrá la siguiente estructura:
	\begin{em}
      	\begin{quote}
      		.SILENT: \newline
		CFLAGS=-I/usr/include/lam -L/usr/lib/lam \newline
		CC=mpicc \newline
		nombre{\_}programa : nombre{\_}programa.c
		\$(CC) \$(CFLAGS) nombre\_programa.c -o nombreprograma
	\end{quote}
	\end{em}
	Para compilar los programas LAM/MPI se utilizará el siguiente comando:
	
	\begin{quote}\textit{\$$>$make -f makefile}\end{quote}
	
	Una vez compilado el programa y antes de ejecutarlo se necesitará primero arrancar el sistem Multicomputador
de Area Local, esto se hace a través del comando \textit{lamboot}.

	Para ejecutar el programa se utilizará el siguiente comando:
	
	\begin{quote}\textit{\$$>$mpirun --np n$^{o}$ de procesos nombre\_programa argumentos}\end{quote}

